{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48257bd9-d358-4221-b121-6486f2449168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfe39c24-c811-4b96-b98e-7f1269257e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 Dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90cde9c7-2fd6-4823-8e52-7074b2ef364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the Model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Unfreeze more layers for better fine-tuning\n",
    "for layer in base_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compile the Model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for better training\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(filepath='vgg16_cifar10_best.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f976ba-cda0-4188-bcca-eca24842652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.2891 - loss: 2.5756\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52970, saving model to vgg16_cifar10_best.keras\n",
      "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 325ms/step - accuracy: 0.2892 - loss: 2.5751 - val_accuracy: 0.5297 - val_loss: 1.5705 - learning_rate: 5.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m  1/781\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 286ms/step - accuracy: 0.5469 - loss: 1.4262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 18:49:28.518016: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.52970\n",
      "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.5469 - loss: 1.4262 - val_accuracy: 0.5243 - val_loss: 1.5958 - learning_rate: 5.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.4629 - loss: 1.7566\n",
      "Epoch 3: val_accuracy improved from 0.52970 to 0.59640, saving model to vgg16_cifar10_best.keras\n",
      "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 337ms/step - accuracy: 0.4629 - loss: 1.7565 - val_accuracy: 0.5964 - val_loss: 1.3045 - learning_rate: 5.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m  1/781\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:23\u001b[0m 415ms/step - accuracy: 0.3750 - loss: 1.9567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 18:54:22.401592: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.59640\n",
      "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.3750 - loss: 1.9567 - val_accuracy: 0.5957 - val_loss: 1.3094 - learning_rate: 5.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m410/781\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 298ms/step - accuracy: 0.5092 - loss: 1.5655"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_train) // batch_size,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[reduce_lr, early_stopping, model_checkpoint])\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Save the Model\n",
    "model.save('vgg16_cifar10_custom_augmented_final.keras', save_format='tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1257a3-3c2d-4a60-9ad9-ec0e2400e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628500e-41b6-4406-96be-65417cf07172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model using random samples\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck','lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "\n",
    "# Get some random test images\n",
    "for x in range(0, 10):\n",
    "    num_images = 5\n",
    "    random_indices = np.random.choice(len(X_test), num_images, replace=False)\n",
    "    test_images = X_test[random_indices]\n",
    "    test_labels = y_test[random_indices]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(test_images)\n",
    "    \n",
    "    # Plot the images with their predicted labels\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(test_images[i])  # Removed interpolation to reduce blur\n",
    "        plt.axis('off')\n",
    "        predicted_label = class_names[np.argmax(predictions[i])]\n",
    "        true_label = class_names[np.argmax(test_labels[i])]\n",
    "        plt.title(f\"Pred: {predicted_label}\\nTrue: {true_label}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
